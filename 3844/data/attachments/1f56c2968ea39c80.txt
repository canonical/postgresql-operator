[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:544 starting continuous writes to the database
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:547 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'test.postgresql-0': 198, 'test.postgresql-2': 199}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'test.postgresql-0': 358, 'test.postgresql-2': 359}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:551 scaling out the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Primary
  postgresql/2 [idle] active: 
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] maintenance: reconfiguring cluster
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] maintenance: reconfiguring cluster
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: 
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/2 [executing] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Primary
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:555 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'test.postgresql-0': 22320, 'test.postgresql-2': 22321, 'test-other.postgresql-0': 22322, 'test-other.postgresql-2': 22322}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'test.postgresql-0': 22439, 'test.postgresql-2': 22440, 'test-other.postgresql-0': 22440, 'test-other.postgresql-2': 22441}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:558 scaling out the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [idle] active: Standby
  postgresql/2 [idle] active: 
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: agent initialising
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: Standby
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] maintenance: reconfiguring cluster
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] maintenance: reconfiguring cluster
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: Standby
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [idle] active: Standby
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: Standby
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: Standby
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: Waiting for the database to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: Standby
  postgresql/2 [executing] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [idle] active: Standby
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:564 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'test.postgresql-0': 44463, 'test.postgresql-2': 44464, 'test-other.postgresql-0': 44465, 'test-other.postgresql-2': 44466}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'test.postgresql-0': 44780, 'test.postgresql-2': 44780, 'test-other.postgresql-0': 44781, 'test-other.postgresql-2': 44782}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:567 scaling in the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [idle] active: Primary
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [executing] active: Primary
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [idle] active: Primary
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:570 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'test.postgresql-2': 50966, 'test.postgresql-3': 50967, 'test-other.postgresql-2': 50967, 'test-other.postgresql-3': 50968}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'test.postgresql-2': 51106, 'test.postgresql-3': 51107, 'test-other.postgresql-2': 51107, 'test-other.postgresql-3': 51107}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:573 scaling in the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [executing] active: 
  postgresql/3 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [executing] maintenance: reconfiguring cluster
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [executing] active: Standby
  postgresql/3 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [idle] active: Standby
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:578 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'test.postgresql-2': 59165, 'test.postgresql-3': 59167, 'test-other.postgresql-2': 59167, 'test-other.postgresql-3': 59168}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'test.postgresql-2': 59297, 'test.postgresql-3': 59298, 'test-other.postgresql-2': 59298, 'test-other.postgresql-3': 59299}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:583 checking whether no writes were lost
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:82 Destroying second model
[32mINFO    [0m pytest_operator.plugin:plugin.py:929 Model status:

Model  Controller           Cloud/Region         Version  SLA          Timestamp
test   localhost-localhost  localhost/localhost  3.6.1    unsupported  03:10:28Z

App                  Version  Status  Scale  Charm                Channel      Rev  Exposed  Message
data-integrator               active      1  data-integrator      latest/edge   80  no       
postgresql           14.15    active      2  postgresql                          0  no       Primary
postgresql-test-app           active      1  postgresql-test-app  latest/edge  322  no       received database credentials of the first database

Unit                    Workload  Agent  Machine  Public address  Ports     Message
data-integrator/0*      active    idle   3        10.96.20.80               
postgresql-test-app/0*  active    idle   4        10.96.20.38               received database credentials of the first database
postgresql/2            active    idle   2        10.96.20.84     5432/tcp  Primary
postgresql/3*           active    idle   5        10.96.20.86     5432/tcp  

Machine  State    Address      Inst id        Base          AZ  Message
2        started  10.96.20.84  juju-206599-2  ubuntu@22.04      Running
3        started  10.96.20.80  juju-206599-3  ubuntu@22.04      Running
4        started  10.96.20.38  juju-206599-4  ubuntu@22.04      Running
5        started  10.96.20.86  juju-206599-5  ubuntu@22.04      Running

Offer              Application  Charm       Rev  Connected  Endpoint           Interface         Role
replication        postgresql   postgresql  0    0/0        replication        postgresql_async  requirer
replication-offer  postgresql   postgresql  0    1/1        replication-offer  postgresql_async  provider

[32mINFO    [0m pytest_operator.plugin:plugin.py:935 Juju error logs:

machine-0: 01:52:15 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:52:15 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-0: 01:52:16 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-2: 01:52:23 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:52:23 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:52:23 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:52:23 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-2: 01:52:24 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-postgresql-1: 01:52:24 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-3: 01:52:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:52:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-data-integrator-0: 01:52:32 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:54:09 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:54:09 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-test-app-0: 01:54:10 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-postgresql-0: 01:54:47 ERROR unit.postgresql/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f0d5f6e6740>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.96.20.162', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0d5f6e6740>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 531, in are_replicas_up
    response = requests.get(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.96.20.162', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0d5f6e6740>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-postgresql-0: 02:13:32 ERROR unit.postgresql/0.juju-log database-peers:2: Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f3d3abd8220>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.96.20.162', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3d3abd8220>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 531, in are_replicas_up
    response = requests.get(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.96.20.162', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f3d3abd8220>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-postgresql-2: 02:28:16 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: relation scope id "55dad217-dc13-481a-8d79-31ccf8206599:r#7#remote-36a0139412b748df84de8d6cdfc10ab7": settings 55dad217-dc13-481a-8d79-31ccf8206599:r#7#remote-36a0139412b748df84de8d6cdfc10ab7 not found (not found)
machine-5: 02:48:29 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 02:48:29 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-3: 02:48:29 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk

[32mINFO    [0m pytest_operator.plugin:plugin.py:1017 Forgetting model main...