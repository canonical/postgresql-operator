[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:77 creating a table in the database
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:85 Downscaling the existing cluster
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:94 Upscaling the second cluster with the old data
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] maintenance: reconfiguring cluster
  second-cluster/2 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] active: Primary
  second-cluster/2 [executing] active: 
  second-cluster/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [executing] active: 
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:105 checking that data was persisted
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.14   unsupported  00:23:36Z

App             Version  Status  Scale  Charm       Channel  Rev  Exposed  Message
second-cluster  14.20    active      3  postgresql             1  no       

Unit               Workload  Agent  Machine  Public address  Ports     Message
second-cluster/1*  active    idle   4        10.12.136.143   5432/tcp  Primary
second-cluster/2   active    idle   5        10.12.136.81    5432/tcp  
second-cluster/3   active    idle   6        10.12.136.168   5432/tcp  

Machine  State    Address        Inst id        Base          AZ             Message
4        started  10.12.136.143  juju-0285f1-4  ubuntu@22.04  runnervmjduv7  Running
5        started  10.12.136.81   juju-0285f1-5  ubuntu@22.04  runnervmjduv7  Running
6        started  10.12.136.168  juju-0285f1-6  ubuntu@22.04  runnervmjduv7  Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

machine-0: 00:09:22 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 00:09:22 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-first-cluster-0: 00:10:40 ERROR unit.first-cluster/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fd408e15000 state=finished raised Exception>]
unit-first-cluster-0: 00:10:58 ERROR unit.first-cluster/0.juju-log Failed to list PostgreSQL database users: could not translate host name "None" to address: Temporary failure in name resolution

machine-1: 00:11:28 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 00:11:28 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 00:11:48 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 00:11:48 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 00:11:54 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 00:11:54 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-first-cluster-1: 00:12:57 ERROR unit.first-cluster/1.juju-log Failed to start patroni snap service
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-first-cluster-1/charm/venv/lib/python3.10/site-packages/charmlibs/snap/_snap.py", line 351, in _snap_daemons
    return subprocess.run(args, text=True, check=True, capture_output=True)
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['snap', 'start', 'charmed-postgresql.patroni']' returned non-zero exit status 1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-first-cluster-1/charm/src/cluster.py", line 713, in start_patroni
    selected_snap.start(services=["patroni"])
  File "/var/lib/juju/agents/unit-first-cluster-1/charm/venv/lib/python3.10/site-packages/charmlibs/snap/_snap.py", line 415, in start
    self._snap_daemons(args, services)
  File "/var/lib/juju/agents/unit-first-cluster-1/charm/venv/lib/python3.10/site-packages/charmlibs/snap/_snap.py", line 354, in _snap_daemons
    raise SnapError._from_called_process_error(msg=msg, error=e) from e
charmlibs.snap._snap.SnapError: Snap: 'charmed-postgresql' -- command ['snap', 'start', 'charmed-postgresql.patroni'] failed!
Stderr:
error: cannot perform the following tasks:
- Run service command "start" for services ["patroni"] of snap "charmed-postgresql" (systemctl command [start snap.charmed-postgresql.patroni.service] failed with exit status 1: stderr:
Job for snap.charmed-postgresql.patroni.service failed because the control process exited with error code.
See "systemctl status snap.charmed-postgresql.patroni.service" and "journalctl -xeu snap.charmed-postgresql.patroni.service" for details.)

Latest logs:
Feb 16 00:11:19 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:11:27 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:11:27 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:11:27 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:11:43 juju-0285f1-1 snapd[340]: api_snaps.go:536: Installing snap "charmed-postgresql" revision 245
Feb 16 00:11:44 juju-0285f1-1 groupadd[3476]: group added to /etc/group: name=snapd-range-524288-root, GID=524288
Feb 16 00:11:44 juju-0285f1-1 groupadd[3476]: group added to /etc/gshadow: name=snapd-range-524288-root
Feb 16 00:11:44 juju-0285f1-1 groupadd[3476]: new group: name=snapd-range-524288-root, GID=524288
Feb 16 00:11:44 juju-0285f1-1 useradd[3482]: new user: name=snapd-range-524288-root, UID=524288, GID=524288, home=/nonexistent, shell=/usr/bin/false, from=none
Feb 16 00:11:44 juju-0285f1-1 groupadd[3489]: group added to /etc/group: name=snap_daemon, GID=584788
Feb 16 00:11:44 juju-0285f1-1 groupadd[3489]: group added to /etc/gshadow: name=snap_daemon
Feb 16 00:11:44 juju-0285f1-1 groupadd[3489]: new group: name=snap_daemon, GID=584788
Feb 16 00:11:44 juju-0285f1-1 useradd[3495]: new user: name=snap_daemon, UID=584788, GID=584788, home=/nonexistent, shell=/usr/bin/false, from=none
Feb 16 00:11:49 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:11:56 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:12:07 juju-0285f1-1 systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
Feb 16 00:12:08 juju-0285f1-1 snapd[340]: backend.go:285: reloading profiles of snap-confine provided by the system snap
Feb 16 00:12:57 juju-0285f1-1 snapd[340]: taskrunner.go:304: Change 10 task (Run service command "start" for services ["patroni"] of snap "charmed-postgresql") failed: systemctl command [start snap.charmed-postgresql.patroni.service] failed with exit status 1: stderr:
Feb 16 00:12:57 juju-0285f1-1 snapd[340]: Job for snap.charmed-postgresql.patroni.service failed because the control process exited with error code.
Feb 16 00:12:57 juju-0285f1-1 snapd[340]: See "systemctl status snap.charmed-postgresql.patroni.service" and "journalctl -xeu snap.charmed-postgresql.patroni.service" for details.

unit-second-cluster-0: 00:13:04 ERROR unit.second-cluster/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f06b8fc14e0 state=finished raised Exception>]
unit-second-cluster-0: 00:13:22 ERROR unit.second-cluster/0.juju-log Failed to list PostgreSQL database users: could not translate host name "None" to address: Temporary failure in name resolution

unit-first-cluster-1: 00:13:23 ERROR unit.first-cluster/1.juju-log restart:2: Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?

unit-first-cluster-2: 00:13:28 ERROR unit.first-cluster/2.juju-log database-peers:1: Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?

unit-second-cluster-0: 00:14:55 ERROR unit.second-cluster/0.juju-log Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: FATAL:  password authentication failed for user "operator"

machine-4: 00:16:42 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 00:16:42 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-second-cluster-1: 00:17:17 ERROR unit.second-cluster/1.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f195e28e650 state=finished raised Exception>]
unit-second-cluster-1: 00:17:19 ERROR unit.second-cluster/1.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f4058651450 state=finished raised Exception>]
unit-second-cluster-1: 00:17:48 ERROR unit.second-cluster/1.juju-log failed to change plugins: 
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 442, in enable_disable_extensions
    with self._connect_to_database() as connection, connection.cursor() as cursor:
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 184, in _connect_to_database
    connection = psycopg2.connect(
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "None" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/charm.py", line 1255, in enable_disable_extensions
    self.postgresql.enable_disable_extensions(extensions, database)
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 471, in enable_disable_extensions
    raise PostgreSQLEnableDisableExtensionError() from e
charms.postgresql_k8s.v0.postgresql.PostgreSQLEnableDisableExtensionError
machine-5: 00:19:04 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 00:19:04 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 00:21:47 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 00:21:47 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...