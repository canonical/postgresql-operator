[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:77 creating a table in the database
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:85 Downscaling the existing cluster
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:94 Upscaling the second cluster with the old data
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [executing] waiting: agent initialising
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] active: Primary (degraded)
  second-cluster/2 [executing] active: 
  second-cluster/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:105 checking that data was persisted
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.14   unsupported  00:25:54Z

App             Version  Status  Scale  Charm       Channel  Rev  Exposed  Message
second-cluster  14.20    active      3  postgresql             1  no       

Unit               Workload  Agent  Machine  Public address  Ports     Message
second-cluster/1*  active    idle   4        10.39.212.4     5432/tcp  Primary
second-cluster/2   active    idle   5        10.39.212.85    5432/tcp  
second-cluster/3   active    idle   6        10.39.212.10    5432/tcp  

Machine  State    Address       Inst id        Base          AZ             Message
4        started  10.39.212.4   juju-efe2ea-4  ubuntu@22.04  runnervmkj6or  Running
5        started  10.39.212.85  juju-efe2ea-5  ubuntu@22.04  runnervmkj6or  Running
6        started  10.39.212.10  juju-efe2ea-6  ubuntu@22.04  runnervmkj6or  Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

machine-0: 00:11:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 00:11:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-first-cluster-0: 00:12:42 ERROR unit.first-cluster/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f113199f430 state=finished raised Exception>]
unit-first-cluster-0: 00:13:03 ERROR unit.first-cluster/0.juju-log Failed to list PostgreSQL database users: could not translate host name "None" to address: Temporary failure in name resolution

machine-1: 00:13:26 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 00:13:26 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 00:13:43 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 00:13:43 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 00:13:56 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 00:13:56 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-second-cluster-0: 00:15:04 ERROR unit.second-cluster/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fb2977bb460 state=finished raised Exception>]
unit-second-cluster-0: 00:15:18 ERROR unit.second-cluster/0.juju-log Failed to list PostgreSQL database users: could not translate host name "None" to address: Temporary failure in name resolution

unit-first-cluster-2: 00:15:50 ERROR unit.first-cluster/2.juju-log database-peers:2: Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?

unit-second-cluster-0: 00:17:00 ERROR unit.second-cluster/0.juju-log Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: FATAL:  password authentication failed for user "operator"

machine-4: 00:18:46 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 00:18:46 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-second-cluster-1: 00:19:44 ERROR unit.second-cluster/1.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fa579f19480 state=finished raised Exception>]
unit-second-cluster-1: 00:19:46 ERROR unit.second-cluster/1.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f900f5c5480 state=finished raised Exception>]
unit-second-cluster-1: 00:20:07 ERROR unit.second-cluster/1.juju-log failed to change plugins: 
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 438, in enable_disable_extensions
    with self._connect_to_database() as connection, connection.cursor() as cursor:
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 184, in _connect_to_database
    connection = psycopg2.connect(
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "None" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/charm.py", line 1258, in enable_disable_extensions
    self.postgresql.enable_disable_extensions(extensions, database)
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 467, in enable_disable_extensions
    raise PostgreSQLEnableDisableExtensionError() from e
charms.postgresql_k8s.v0.postgresql.PostgreSQLEnableDisableExtensionError
machine-5: 00:21:23 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 00:21:23 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 00:24:03 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 00:24:03 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...