[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:77 creating a table in the database
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:85 Downscaling the existing cluster
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:94 Upscaling the second cluster with the old data
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/2 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] active: Primary (degraded)
  second-cluster/2 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] active: Primary
  second-cluster/2 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/3 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [executing] active: Primary (degraded)
  second-cluster/2 [executing] active: 
  second-cluster/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
  second-cluster/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  second-cluster/1 [idle] active: Primary
  second-cluster/2 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_restore_cluster:test_restore_cluster.py:105 checking that data was persisted
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.14   unsupported  00:23:48Z

App             Version  Status  Scale  Charm       Channel  Rev  Exposed  Message
second-cluster  14.20    active      3  postgresql             1  no       

Unit               Workload  Agent  Machine  Public address  Ports     Message
second-cluster/1*  active    idle   4        10.223.92.190   5432/tcp  Primary
second-cluster/2   active    idle   5        10.223.92.178   5432/tcp  
second-cluster/3   active    idle   6        10.223.92.18    5432/tcp  

Machine  State    Address        Inst id        Base          AZ             Message
4        started  10.223.92.190  juju-4de12d-4  ubuntu@22.04  runnervmjduv7  Running
5        started  10.223.92.178  juju-4de12d-5  ubuntu@22.04  runnervmjduv7  Running
6        started  10.223.92.18   juju-4de12d-6  ubuntu@22.04  runnervmjduv7  Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

machine-0: 00:10:19 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 00:10:19 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-first-cluster-0: 00:11:06 ERROR unit.first-cluster/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-first-cluster-0/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fd16f16ab30 state=finished raised Exception>]
unit-first-cluster-0: 00:11:28 ERROR unit.first-cluster/0.juju-log Failed to list PostgreSQL database users: could not translate host name "None" to address: Temporary failure in name resolution

machine-1: 00:12:13 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 00:12:13 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 00:12:24 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 00:12:24 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 00:12:40 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 00:12:40 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-first-cluster-1: 00:13:39 ERROR unit.first-cluster/1.juju-log restart:1: Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?

unit-second-cluster-0: 00:13:46 ERROR unit.second-cluster/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-0/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f297aef54b0 state=finished raised Exception>]
unit-first-cluster-2: 00:14:08 ERROR unit.first-cluster/2.juju-log upgrade:2: Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: No such file or directory
	Is the server running locally and accepting connections on that socket?

unit-second-cluster-0: 00:15:24 ERROR unit.second-cluster/0.juju-log Failed to list PostgreSQL database users: connection to server on socket "/tmp/snap-private-tmp/snap.charmed-postgresql/tmp//.s.PGSQL.5432" failed: FATAL:  password authentication failed for user "operator"

machine-4: 00:17:04 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 00:17:04 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-second-cluster-1: 00:17:35 ERROR unit.second-cluster/1.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7efd3ba7e680 state=finished raised Exception>]
unit-second-cluster-1: 00:17:37 ERROR unit.second-cluster/1.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 569, in are_replicas_up
    members = self.cluster_status()
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/cluster.py", line 369, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fe721bc9480 state=finished raised Exception>]
unit-second-cluster-1: 00:18:06 ERROR unit.second-cluster/1.juju-log failed to change plugins: 
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 442, in enable_disable_extensions
    with self._connect_to_database() as connection, connection.cursor() as cursor:
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 184, in _connect_to_database
    connection = psycopg2.connect(
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "None" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/src/charm.py", line 1255, in enable_disable_extensions
    self.postgresql.enable_disable_extensions(extensions, database)
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-second-cluster-1/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 471, in enable_disable_extensions
    raise PostgreSQLEnableDisableExtensionError() from e
charms.postgresql_k8s.v0.postgresql.PostgreSQLEnableDisableExtensionError
machine-5: 00:19:14 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 00:19:14 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 00:21:47 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-6: 00:21:47 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...