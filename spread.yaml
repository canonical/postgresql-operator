project: postgresql-operator

backends:
  # Derived from https://github.com/jnsgruk/zinc-k8s-operator/blob/a21eae8399eb3b9df4ddb934b837af25ef831976/spread.yaml#L11
  lxd-vm:
    # TODO: remove after https://github.com/canonical/spread/pull/185 merged & in charmcraft
    type: adhoc
    allocate: |
      hash=$(python3 -c "import hashlib; print(hashlib.sha256('$SPREAD_PASSWORD'.encode()).hexdigest()[:6])")
      VM_NAME="${VM_NAME:-${SPREAD_SYSTEM//./-}-${hash}}"
      DISK="${DISK:-20}"
      CPU="${CPU:-4}"
      MEM="${MEM:-8}"

      cloud_config="#cloud-config
      ssh_pwauth: true
      users:
        - default
        - name: runner
          plain_text_passwd: $SPREAD_PASSWORD
          lock_passwd: false
          sudo: ALL=(ALL) NOPASSWD:ALL
      "

      lxc launch --vm \
        "${SPREAD_SYSTEM//-/:}" \
        "${VM_NAME}" \
        -c user.user-data="${cloud_config}" \
        -c limits.cpu="${CPU}" \
        -c limits.memory="${MEM}GiB" \
        -d root,size="${DISK}GiB"

      # Wait for the runner user
      while ! lxc exec "${VM_NAME}" -- id -u runner &>/dev/null; do sleep 0.5; done

      # Set the instance address for spread
      ADDRESS "$(lxc ls -f csv | grep "${VM_NAME}" | cut -d"," -f3 | cut -d" " -f1)"
    discard: |
      hash=$(python3 -c "import hashlib; print(hashlib.sha256('$SPREAD_PASSWORD'.encode()).hexdigest()[:6])")
      VM_NAME="${VM_NAME:-${SPREAD_SYSTEM//./-}-${hash}}"
      lxc delete --force "${VM_NAME}"
    environment:
      CONCIERGE_EXTRA_SNAPS: charmcraft
      CONCIERGE_EXTRA_DEBS: pipx
    systems:
      - ubuntu-24.04:
          username: runner
    prepare: |
      systemctl disable --now unattended-upgrades.service
      systemctl mask unattended-upgrades.service
      pipx install charmcraftcache
      cd "$SPREAD_PATH"
      charmcraftcache pack -v
    restore-each: |
      cd "$SPREAD_PATH"
      # Revert python-libjuju version override
      git restore pyproject.toml poetry.lock

      # Use instead of `concierge restore` to save time between tests
      # For example, with microk8s, using `concierge restore` takes twice as long as this (e.g. 6
      # min instead of 3 min between every spread job)
      juju destroy-model --force --no-wait --destroy-storage --no-prompt testing
      juju kill-controller --no-prompt concierge-lxd
    restore: |
      rm -rf "$SPREAD_PATH"

  github-ci:
    type: adhoc
    # Only run on CI
    manual: true
    # HACK: spread requires runners to be accessible via SSH
    # Configure local sshd & instruct spread to connect to the same machine spread is running on
    # (spread cannot provision GitHub Actions runners, so we provision a GitHub Actions runner for
    # each spread job & select a single job when running spread)
    # Derived from https://github.com/jnsgruk/zinc-k8s-operator/blob/a21eae8399eb3b9df4ddb934b837af25ef831976/spread.yaml#L47
    allocate: |
      sudo tee /etc/ssh/sshd_config.d/10-spread-github-ci.conf << 'EOF'
      PasswordAuthentication yes
      EOF

      echo "runner:$SPREAD_PASSWORD" | sudo chpasswd

      ADDRESS localhost

      sudo mkdir -p /var/snap/lxd/common/lxd/storage-pools
      sudo mount --bind /mnt /var/snap/lxd/common/lxd/storage-pools
    # HACK: spread does not pass environment variables set on runner
    # Manually pass specific environment variables
    environment:
      CI: '$(HOST: echo $CI)'
      AWS_ACCESS_KEY: '$(HOST: echo $AWS_ACCESS_KEY)'
      AWS_SECRET_KEY: '$(HOST: echo $AWS_SECRET_KEY)'
      GCP_ACCESS_KEY: '$(HOST: echo $GCP_ACCESS_KEY)'
      GCP_SECRET_KEY: '$(HOST: echo $GCP_SECRET_KEY)'
      UBUNTU_PRO_TOKEN: '$(HOST: echo $UBUNTU_PRO_TOKEN)'
      LANDSCAPE_ACCOUNT_NAME: '$(HOST: echo $LANDSCAPE_ACCOUNT_NAME)'
      LANDSCAPE_REGISTRATION_KEY: '$(HOST: echo $LANDSCAPE_REGISTRATION_KEY)'
    systems:
      - ubuntu-24.04:
          username: runner
      - ubuntu-22.04-arm:
          username: runner
          variants:
            - -juju29

suites:
  tests/spread/:
    summary: Spread tests

path: /root/spread_project

kill-timeout: 3h
environment:
  PATH: /usr/local/bin:$PATH:$(pipx environment --value PIPX_BIN_DIR)
  CONCIERGE_JUJU_CHANNEL/juju36: 3.6/stable
  CONCIERGE_JUJU_CHANNEL/juju29: 2.9/stable
prepare: |
  snap refresh --hold
  chown -R root:root "$SPREAD_PATH"
  cd "$SPREAD_PATH"
  snap install --classic concierge

  # Install Go 1.25.5 (required for custom Juju build)
  ARCH=$(dpkg --print-architecture)
  GO_VERSION="1.25.5"
  
  if [ ! -f /usr/local/go/bin/go ] || [ "$(/usr/local/go/bin/go version | awk '{print $3}')" != "go${GO_VERSION}" ]; then
    echo "Installing Go ${GO_VERSION}..."
    wget -q "https://go.dev/dl/go${GO_VERSION}.linux-${ARCH}.tar.gz"
    rm -rf /usr/local/go
    tar -C /usr/local -xzf "go${GO_VERSION}.linux-${ARCH}.tar.gz"
    rm "go${GO_VERSION}.linux-${ARCH}.tar.gz"
  fi
  
  # Install build dependencies for Juju
  apt-get update -qq
  DEBIAN_FRONTEND=noninteractive apt-get install -y -qq build-essential git

  # Install charmcraft & pipx (on lxd-vm backend)
  concierge prepare --trace

  pipx install tox poetry
prepare-each: |
  cd "$SPREAD_PATH"
  if [[ $SPREAD_VARIANT == *"juju29"* ]]
  then
    # Each version of python-libjuju is only compatible with one major Juju version
    # Override python-libjuju version pinned in poetry.lock
    poetry add --lock --group integration juju@^2
  fi
  # `concierge prepare` needs to be run for each spread job in case Juju version changed
  concierge prepare --trace
  
  juju kill-controller -t 1s --no-prompt concierge-lxd
  
  # Check if Juju is version 3.x and build custom version if so
  JUJU_VERSION=$(juju version 2>&1 | head -1)
  if [[ $JUJU_VERSION == "3."* ]]; then
    # Build custom Juju from source for 3.x variants
    export PATH=/usr/local/go/bin:$PATH
    export GOPATH=/root/go
    export JUJU_BUILD_DIR=/opt/juju-custom
    export JUJU_CACHE_BINARY=$JUJU_BUILD_DIR/juju-binary
    export JUJU_REPO=https://github.com/marceloneppel/juju.git
    export JUJU_BRANCH=allow-timeouts-configuration
    
    mkdir -p "$JUJU_BUILD_DIR"
    
    # Clone or update repository
    if [ ! -d "$JUJU_BUILD_DIR/.git" ]; then
      echo "Cloning Juju from $JUJU_REPO (branch: $JUJU_BRANCH)..."
      git clone --depth 1 --branch "$JUJU_BRANCH" "$JUJU_REPO" "$JUJU_BUILD_DIR"
    else
      echo "Updating Juju repository..."
      cd "$JUJU_BUILD_DIR"
      git fetch origin "$JUJU_BRANCH"
      git reset --hard "origin/$JUJU_BRANCH"
      git clean -fdx
    fi
    
    cd "$JUJU_BUILD_DIR"
    CURRENT_COMMIT=$(git rev-parse HEAD)
    
    # Check if we can use cached binary
    REBUILD_NEEDED=true
    if [ -f "$JUJU_CACHE_BINARY" ] && [ -f "$JUJU_BUILD_DIR/.build_commit" ]; then
      CACHED_COMMIT=$(cat "$JUJU_BUILD_DIR/.build_commit")
      if [ "$CURRENT_COMMIT" = "$CACHED_COMMIT" ]; then
        echo "Using cached Juju binary (commit: $CURRENT_COMMIT)"
        REBUILD_NEEDED=false
        cp "$JUJU_CACHE_BINARY" /usr/local/bin/juju
        chmod +x /usr/local/bin/juju
      fi
    fi
    
    # Build if needed
    if [ "$REBUILD_NEEDED" = true ]; then
      echo "Building Juju from source (commit: $CURRENT_COMMIT)..."
      
      # Build using make install (installs to $GOPATH/bin by default)
      make install || {
        echo "ERROR: Failed to build Juju from source"
        exit 1
      }
      
      # Copy built binary from GOPATH to /usr/local/bin
      if [ -f "$GOPATH/bin/juju" ]; then
        cp "$GOPATH/bin/juju" /usr/local/bin/juju
        chmod +x /usr/local/bin/juju
        
        # Cache the binary for future runs
        cp /usr/local/bin/juju "$JUJU_CACHE_BINARY"
        echo "$CURRENT_COMMIT" > "$JUJU_BUILD_DIR/.build_commit"
        
        echo "Build complete and cached"
      else
        echo "ERROR: Built binary not found at $GOPATH/bin/juju"
        exit 1
      fi
      
      # Clean up Go build cache to save disk space
      echo "Cleaning Go build cache..."
      go clean -cache -modcache
    fi
    
    # Verify installation
    echo "Juju binary location: $(which juju)"
    echo "Juju version: $(juju version)"
    
    # Bootstrap with --build-agent for custom Juju 3.x build
    juju bootstrap localhost concierge-lxd --build-agent --config read-timeout=3600s --config write-timeout=3600s --verbose
  else
    echo "Juju version is not 3.x (detected: $JUJU_VERSION), skipping custom build"
    
    # Bootstrap without --build-agent for official Juju 2.9.x snap
    juju bootstrap localhost concierge-lxd --config read-timeout=3600s --config write-timeout=3600s --verbose
  fi
  
  juju add-model -c concierge-lxd testing
  
  cd "$SPREAD_PATH"

  # Unable to set constraint on all models because of Juju bug:
  # https://bugs.launchpad.net/juju/+bug/2065050
  juju set-model-constraints arch="$(dpkg --print-architecture)"
# Only restore on lxd backendâ€”no need to restore on CI
