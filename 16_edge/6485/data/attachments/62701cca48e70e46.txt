[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:268 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:273 Cutting network for postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:281 checking for no connectivity between postgresql/2 and postgresql/0
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:281 checking for no connectivity between postgresql/2 and postgresql/1
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:288 checking for no connectivity between postgresql/2 and the controller
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:295 checking whether the connectivity to the database is not working
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:301 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:104 Initial writes {'testing.postgresql-0': 131, 'testing.postgresql-1': 131}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:114 Retry writes {'testing.postgresql-0': 133, 'testing.postgresql-1': 133}
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:304 checking whether a new primary was elected
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:311 Restoring network for postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:315 waiting for cluster to become idle
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/1 [idle] active: Primary (degraded)
  postgresql/2 [idle] active: Primary
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:320 waiting for the database service to be ready on postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:324 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:223 checking that the former primary is now a replica
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:229 checking that all units are part of the same cluster
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:243 checking that no writes to the database were missed after stopping the writes
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-0, count: 212, max_number_written: 212, total_expected_writes: 212
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-1, count: 212, max_number_written: 212, total_expected_writes: 212
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-2, count: 212, max_number_written: 212, total_expected_writes: 212
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:249 checking that the former primary is up to date with the cluster after restarting
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.14   unsupported  01:46:43Z

App                  Version  Status  Scale  Charm                Channel      Rev  Exposed  Message
postgresql           16.11    active      3  postgresql                          0  no       
postgresql-test-app           active      1  postgresql-test-app  latest/edge  434  no       received database credentials of the first database

Unit                    Workload  Agent      Machine  Public address  Ports     Message
postgresql-test-app/0*  active    idle       3        10.13.146.173             received database credentials of the first database
postgresql/0            active    idle       0        10.13.146.234   5432/tcp  
postgresql/1*           active    executing  1        10.13.146.82    5432/tcp  Primary
postgresql/2            active    executing  2        10.13.146.155   5432/tcp  

Machine  State    Address        Inst id        Base          AZ             Message
0        started  10.13.146.234  juju-ed0754-0  ubuntu@24.04  runnervmkj6or  Running
1        started  10.13.146.82   juju-ed0754-1  ubuntu@24.04  runnervmkj6or  Running
2        started  10.13.146.155  juju-ed0754-2  ubuntu@24.04  runnervmkj6or  Running
3        started  10.13.146.173  juju-ed0754-3  ubuntu@22.04  runnervmkj6or  Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

machine-0: 01:34:10 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:34:10 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:34:23 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:34:23 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:34:30 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:34:30 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:34:43 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:34:43 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-0: 01:35:19 ERROR unit.postgresql/0.juju-log cluster:Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 592, in online_cluster_members
    cluster_status = self.cluster_status()
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 283, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7ff4fa9bef90 state=finished raised Exception>]
unit-postgresql-0: 01:35:26 ERROR unit.postgresql/0.juju-log cluster:Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 592, in online_cluster_members
    cluster_status = self.cluster_status()
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 283, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7ff0a5812ff0 state=finished raised Exception>]
machine-0: 01:40:53 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b81e08] "machine-0" cannot open api: unable to connect to API: dial tcp 10.13.146.212:17070: connect: network is unreachable
machine-0: 01:40:57 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b81e08] "machine-0" cannot open api: unable to connect to API: dial tcp 10.13.146.212:17070: connect: network is unreachable
machine-0: 01:41:02 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b81e08] "machine-0" cannot open api: unable to connect to API: dial tcp 10.13.146.212:17070: connect: network is unreachable
unit-postgresql-test-app-0: 01:43:43 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-1: 01:44:19 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-2: 01:45:23 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: api connection broken unexpectedly
machine-2: 01:45:26 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b81e08] "machine-2" cannot open api: unable to connect to API: dial tcp 10.13.146.212:17070: connect: no route to host
machine-2: 01:45:32 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b81e08] "machine-2" cannot open api: unable to connect to API: dial tcp 10.13.146.212:17070: connect: no route to host
machine-3: 01:45:36 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-1: 01:45:36 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...