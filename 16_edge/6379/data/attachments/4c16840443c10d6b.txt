[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:268 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:273 Cutting network for postgresql/1
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:281 checking for no connectivity between postgresql/1 and postgresql/0
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:281 checking for no connectivity between postgresql/1 and postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:288 checking for no connectivity between postgresql/1 and the controller
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:295 checking whether the connectivity to the database is not working
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:301 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:104 Initial writes {'testing.postgresql-0': 21, 'testing.postgresql-2': 21}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:114 Retry writes {'testing.postgresql-0': 23, 'testing.postgresql-2': 23}
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:304 checking whether a new primary was elected
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:311 Restoring network for postgresql/1
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:315 waiting for cluster to become idle
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/1 [idle] active: Primary
  postgresql/2 [idle] active: Primary (degraded)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/1 [idle] active: 
  postgresql/2 [executing] active: Primary
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:320 waiting for the database service to be ready on postgresql/1
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:324 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:223 checking that the former primary is now a replica
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:229 checking that all units are part of the same cluster
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:243 checking that no writes to the database were missed after stopping the writes
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-0, count: 142, max_number_written: 142, total_expected_writes: 142
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-1, count: 142, max_number_written: 142, total_expected_writes: 142
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-2, count: 142, max_number_written: 142, total_expected_writes: 142
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:249 checking that the former primary is up to date with the cluster after restarting
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.13   unsupported  02:04:06Z

App                  Version  Status  Scale  Charm                Channel      Rev  Exposed  Message
postgresql           16.11    active      3  postgresql                          0  no       
postgresql-test-app           active      1  postgresql-test-app  latest/edge  432  no       received database credentials of the first database

Unit                    Workload  Agent  Machine  Public address  Ports     Message
postgresql-test-app/0*  active    idle   3        10.118.178.92             received database credentials of the first database
postgresql/0*           active    idle   0        10.118.178.22   5432/tcp  
postgresql/1            active    idle   1        10.118.178.98   5432/tcp  
postgresql/2            active    idle   2        10.118.178.46   5432/tcp  Primary

Machine  State    Address        Inst id        Base          AZ             Message
0        started  10.118.178.22  juju-887f70-0  ubuntu@24.04  runnervmymu0l  Running
1        started  10.118.178.98  juju-887f70-1  ubuntu@24.04  runnervmymu0l  Running
2        started  10.118.178.46  juju-887f70-2  ubuntu@24.04  runnervmymu0l  Running
3        started  10.118.178.92  juju-887f70-3  ubuntu@22.04  runnervmymu0l  Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

machine-0: 01:51:32 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:51:32 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:51:46 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:51:46 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:51:54 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:51:54 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:52:06 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:52:06 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-0: 01:52:42 ERROR unit.postgresql/0.juju-log cluster:Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 592, in online_cluster_members
    cluster_status = self.cluster_status()
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 283, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f1a2a3b6f60 state=finished raised Exception>]
unit-postgresql-0: 01:52:51 ERROR unit.postgresql/0.juju-log cluster:Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 592, in online_cluster_members
    cluster_status = self.cluster_status()
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 283, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7f2af76df890 state=finished raised Exception>]
machine-0: 01:58:12 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: api connection broken unexpectedly
machine-0: 01:58:15 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [99201c] "machine-0" cannot open api: unable to connect to API: dial tcp 10.118.178.196:17070: connect: network is unreachable
machine-0: 01:58:19 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [99201c] "machine-0" cannot open api: unable to connect to API: dial tcp 10.118.178.196:17070: connect: network is unreachable
machine-0: 01:58:24 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [99201c] "machine-0" cannot open api: unable to connect to API: dial tcp 10.118.178.196:17070: connect: network is unreachable
machine-0: 01:58:29 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [99201c] "machine-0" cannot open api: unable to connect to API: dial tcp 10.118.178.196:17070: connect: network is unreachable
unit-postgresql-test-app-0: 02:01:07 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-2: 02:01:51 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-2: 02:02:49 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-1: 02:02:51 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [99201c] "machine-1" cannot open api: unable to connect to API: dial tcp 10.118.178.196:17070: connect: no route to host
machine-3: 02:02:56 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...