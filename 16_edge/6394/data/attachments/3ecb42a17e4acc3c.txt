[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:268 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:273 Cutting network for postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:281 checking for no connectivity between postgresql/2 and postgresql/0
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:281 checking for no connectivity between postgresql/2 and postgresql/1
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:288 checking for no connectivity between postgresql/2 and the controller
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:295 checking whether the connectivity to the database is not working
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:301 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:104 Initial writes {'testing.postgresql-0': 97, 'testing.postgresql-1': 97}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:114 Retry writes {'testing.postgresql-0': 99, 'testing.postgresql-1': 99}
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:304 checking whether a new primary was elected
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:311 Restoring network for postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:315 waiting for cluster to become idle
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/1 [idle] active: Primary (degraded)
  postgresql/2 [idle] active: Primary
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:320 waiting for the database service to be ready on postgresql/2
[32mINFO    [0m integration.ha_tests.test_self_healing_3:test_self_healing_3.py:324 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:223 checking that the former primary is now a replica
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:229 checking that all units are part of the same cluster
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:243 checking that no writes to the database were missed after stopping the writes
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-0, count: 156, max_number_written: 156, total_expected_writes: 156
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-1, count: 156, max_number_written: 156, total_expected_writes: 156
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:268 member: testing.postgresql-2, count: 156, max_number_written: 156, total_expected_writes: 156
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:249 checking that the former primary is up to date with the cluster after restarting
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.13   unsupported  01:47:09Z

App                  Version  Status  Scale  Charm                Channel      Rev  Exposed  Message
postgresql           16.11    active      3  postgresql                          0  no       
postgresql-test-app           active      1  postgresql-test-app  latest/edge  432  no       received database credentials of the first database

Unit                    Workload  Agent      Machine  Public address  Ports     Message
postgresql-test-app/0*  active    executing  3        10.166.71.218             received database credentials of the first database
postgresql/0            active    executing  0        10.166.71.246   5432/tcp  
postgresql/1*           active    executing  1        10.166.71.183   5432/tcp  Primary
postgresql/2            active    idle       2        10.166.71.120   5432/tcp  

Machine  State    Address        Inst id        Base          AZ             Message
0        started  10.166.71.246  juju-08946b-0  ubuntu@24.04  runnervmymu0l  Running
1        started  10.166.71.183  juju-08946b-1  ubuntu@24.04  runnervmymu0l  Running
2        started  10.166.71.120  juju-08946b-2  ubuntu@24.04  runnervmymu0l  Running
3        started  10.166.71.218  juju-08946b-3  ubuntu@22.04  runnervmymu0l  Running

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

machine-0: 01:34:27 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:34:27 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:34:37 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:34:37 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:34:47 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:34:47 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:35:00 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:35:00 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-0: 01:35:41 ERROR unit.postgresql/0.juju-log cluster:Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 592, in online_cluster_members
    cluster_status = self.cluster_status()
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 283, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fdfce2b6f30 state=finished raised Exception>]
unit-postgresql-0: 01:35:49 ERROR unit.postgresql/0.juju-log cluster:Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 592, in online_cluster_members
    cluster_status = self.cluster_status()
                     ^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1153, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 283, in cluster_status
    raise RetryError(
tenacity.RetryError: RetryError[<Future at 0x7fe8c4943110 state=finished raised Exception>]
unit-postgresql-1: 01:46:01 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-2: 01:46:22 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [17a116] "machine-2" cannot open api: unable to connect to API: dial tcp 10.166.71.82:17070: connect: no route to host
machine-2: 01:46:28 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [17a116] "machine-2" cannot open api: unable to connect to API: dial tcp 10.166.71.82:17070: connect: no route to host
machine-3: 01:46:29 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-1: 01:46:29 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-test-app-0: 01:46:40 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...