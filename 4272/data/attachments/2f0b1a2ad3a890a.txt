[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:532 starting continuous writes to the database
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:535 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'testing.postgresql-0': 210, 'testing.postgresql-2': 211}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'testing.postgresql-0': 371, 'testing.postgresql-2': 372}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:539 scaling out the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Primary
  postgresql/2 [idle] active: 
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: agent initialising
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary (degraded)
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] maintenance: reconfiguring cluster
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] maintenance: reconfiguring cluster
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary (degraded)
  postgresql/2 [executing] active: 
  postgresql/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/2 [idle] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/2 [executing] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: 
  postgresql/2 [idle] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Primary
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: 
  postgresql/2 [idle] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Primary
  postgresql/2 [idle] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: 
  postgresql/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:543 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'testing.postgresql-0': 23000, 'testing.postgresql-2': 23001, 'testing.postgresql-3': 23001, 'testing-other.postgresql-0': 23002, 'testing-other.postgresql-2': 23002, 'testing-other.postgresql-3': 23003}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'testing.postgresql-0': 23121, 'testing.postgresql-2': 23121, 'testing.postgresql-3': 23122, 'testing-other.postgresql-0': 23122, 'testing-other.postgresql-2': 23123, 'testing-other.postgresql-3': 23123}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:546 scaling out the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Standby
  postgresql/1 [idle] active: 
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [allocating] waiting: waiting for machine
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] waiting: agent initialising
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] maintenance: installing PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Standby (degraded)
  postgresql/1 [executing] maintenance: reconfiguring cluster
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Standby (degraded)
  postgresql/1 [executing] maintenance: reconfiguring cluster
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Standby (degraded)
  postgresql/1 [executing] maintenance: reconfiguring cluster
  postgresql/3 [executing] waiting: waiting to start PostgreSQL
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Standby (degraded)
  postgresql/1 [executing] active: 
  postgresql/3 [executing] maintenance: reinitialising replica
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Standby
  postgresql/1 [executing] active: 
  postgresql/3 [executing] waiting: Waiting for the database to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Standby
  postgresql/1 [idle] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Standby
  postgresql/1 [executing] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [executing] active: Standby
  postgresql/1 [executing] active: 
  postgresql/3 [executing] waiting: waiting for primary to be reachable from this unit
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/0 [idle] active: Standby
  postgresql/1 [idle] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:552 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'testing.postgresql-0': 40329, 'testing.postgresql-2': 40330, 'testing.postgresql-3': 40331, 'testing-other.postgresql-0': 40332, 'testing-other.postgresql-2': 40332, 'testing-other.postgresql-3': 40333}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'testing.postgresql-0': 40479, 'testing.postgresql-2': 40479, 'testing.postgresql-3': 40480, 'testing-other.postgresql-0': 40481, 'testing-other.postgresql-2': 40482, 'testing-other.postgresql-3': 40483}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:555 scaling in the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [executing] active: 
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/2 [idle] active: 
  postgresql/3 [executing] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [executing] active: Primary
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/3 [idle] active: Primary
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:558 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'testing.postgresql-2': 48045, 'testing.postgresql-3': 48046, 'testing-other.postgresql-2': 48047, 'testing-other.postgresql-3': 48047}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'testing.postgresql-2': 48162, 'testing.postgresql-3': 48162, 'testing-other.postgresql-2': 48163, 'testing-other.postgresql-3': 48164}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:561 scaling in the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql (waiting for exactly 2 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] waiting: waiting for primary to be reachable from this unit
  postgresql/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: 
  postgresql/3 [idle] active: Standby
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql/1 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:566 checking whether writes are increasing
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:103 Initial writes {'testing.postgresql-2': 55141, 'testing.postgresql-3': 55142, 'testing-other.postgresql-2': 55143, 'testing-other.postgresql-3': 55143}
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:113 Retry writes {'testing.postgresql-2': 55265, 'testing.postgresql-3': 55265, 'testing-other.postgresql-2': 55266, 'testing-other.postgresql-3': 55267}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:571 checking whether no writes were lost
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:82 Destroying second model
[32mINFO    [0m pytest_operator.plugin:plugin.py:936 Model status:

Model    Controller     Cloud/Region         Version  SLA          Timestamp
testing  concierge-lxd  localhost/localhost  3.6.5    unsupported  02:58:49Z

App                  Version  Status  Scale  Charm                Channel      Rev  Exposed  Message
data-integrator               active      1  data-integrator      latest/edge  133  no       
postgresql           14.17    active      2  postgresql                          0  no       Primary
postgresql-test-app           active      1  postgresql-test-app  latest/edge  377  no       received database credentials of the first database

Unit                    Workload  Agent  Machine  Public address  Ports     Message
data-integrator/0*      active    idle   3        10.152.125.35             
postgresql-test-app/0*  active    idle   4        10.152.125.180            received database credentials of the first database
postgresql/2            active    idle   2        10.152.125.74   5432/tcp  
postgresql/3*           active    idle   5        10.152.125.26   5432/tcp  Primary

Machine  State    Address         Inst id        Base          AZ  Message
2        started  10.152.125.74   juju-093678-2  ubuntu@22.04      Running
3        started  10.152.125.35   juju-093678-3  ubuntu@24.04      Running
4        started  10.152.125.180  juju-093678-4  ubuntu@22.04      Running
5        started  10.152.125.26   juju-093678-5  ubuntu@22.04      Running

Offer              Application  Charm       Rev  Connected  Endpoint           Interface         Role
replication        postgresql   postgresql  0    0/0        replication        postgresql_async  requirer
replication-offer  postgresql   postgresql  0    1/1        replication-offer  postgresql_async  provider

[32mINFO    [0m pytest_operator.plugin:plugin.py:942 Juju error logs:

machine-3: 01:42:14 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-3: 01:42:14 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-data-integrator-0: 01:42:15 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-0: 01:43:31 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-0: 01:43:31 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-0: 01:43:31 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-4: 01:45:08 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-4: 01:45:08 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-test-app-0: 01:45:09 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-postgresql-0: 01:46:12 ERROR unit.postgresql/0.juju-log Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f143f3c6470>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.152.125.226', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f143f3c6470>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 552, in are_replicas_up
    response = requests.get(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.152.125.226', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f143f3c6470>: Failed to establish a new connection: [Errno 111] Connection refused'))
machine-2: 01:46:42 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-2: 01:46:42 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-2: 01:46:42 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
machine-1: 01:48:10 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-1: 01:48:10 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-1: 01:48:11 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-postgresql-0: 02:06:49 ERROR unit.postgresql/0.juju-log database-peers:2: Unable to get the state of the cluster
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 493, in _make_request
    conn.request(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 445, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 276, in connect
    self.sock = self._new_conn()
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connection.py", line 213, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f47aedac580>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.152.125.226', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f47aedac580>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-0/charm/src/cluster.py", line 552, in are_replicas_up
    response = requests.get(
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-0/charm/venv/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='10.152.125.226', port=8008): Max retries exceeded with url: /cluster (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f47aedac580>: Failed to establish a new connection: [Errno 111] Connection refused'))
unit-postgresql-2: 02:34:45 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-0: 02:34:47 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-data-integrator-0: 02:34:48 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-test-app-0: 02:34:52 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-0: 02:36:35 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-3: 02:36:35 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-4: 02:36:35 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-2: 02:36:35 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-0: 02:37:18 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-2: 02:37:24 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-data-integrator-0: 02:37:25 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-5: 02:38:08 ERROR juju.worker.dependency "kvm-container-provisioner" manifold worker returned unexpected error: container types not yet available
machine-5: 02:38:08 ERROR juju.worker.dependency "lxd-container-provisioner" manifold worker returned unexpected error: container types not yet available
unit-postgresql-3: 02:38:08 ERROR juju.worker.meterstatus error running "meter-status-changed": charm missing from disk
unit-postgresql-0: 02:40:47 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-3: 02:42:53 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-data-integrator-0: 02:42:58 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-2: 02:42:59 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-0: 02:46:03 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-3: 02:47:34 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-0: 02:50:49 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-2: 02:51:31 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-data-integrator-0: 02:51:32 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-3: 02:55:10 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
machine-5: 02:58:39 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent

[32mINFO    [0m pytest_operator.plugin:plugin.py:1024 Forgetting model main...